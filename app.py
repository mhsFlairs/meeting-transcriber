import streamlit as st
import tempfile
import os
import hashlib
from openai import OpenAI
from moviepy import VideoFileClip
from pathlib import Path
import time

# Initialize session state
if "processed_audio_path" not in st.session_state:
    st.session_state.processed_audio_path = None
if "current_file_hash" not in st.session_state:
    st.session_state.current_file_hash = None
if "conversion_complete" not in st.session_state:
    st.session_state.conversion_complete = False
if "uploaded_file_info" not in st.session_state:
    st.session_state.uploaded_file_info = None
if "transcription_complete" not in st.session_state:
    st.session_state.transcription_complete = False
if "transcription_text" not in st.session_state:
    st.session_state.transcription_text = ""
if "translation_complete" not in st.session_state:
    st.session_state.translation_complete = False
if "translation_text" not in st.session_state:
    st.session_state.translation_text = ""


# Initialize OpenAI client
@st.cache_resource
def get_openai_client():
    return OpenAI()


def get_file_hash(file_bytes):
    """Generate hash for file content to detect changes"""
    return hashlib.md5(file_bytes).hexdigest()


@st.cache_data(show_spinner=False)
def get_file_info(_file_bytes, filename, file_hash):
    """Get detailed information about the file - cached based on content hash"""
    # Create temp file from bytes
    with tempfile.NamedTemporaryFile(
        delete=False, suffix=Path(filename).suffix
    ) as tmp_file:
        tmp_file.write(_file_bytes)
        temp_path = tmp_file.name

    is_video = is_video_file(filename)
    file_info = {
        "size_mb": len(_file_bytes) / (1024 * 1024),
        "format": Path(filename).suffix.lower(),
        "temp_path": temp_path,
        "name": filename,
        "is_video": is_video,
        "is_audio": is_audio_file(filename),
        "hash": file_hash,
    }

    if is_video:
        try:
            with VideoFileClip(temp_path) as video:
                file_info.update(
                    {
                        "duration": video.duration,
                        "fps": video.fps,
                        "resolution": (
                            f"{video.w}x{video.h}" if video.w and video.h else "Unknown"
                        ),
                        "has_audio": video.audio is not None,
                    }
                )
        except Exception as e:
            st.warning(f"Could not read video metadata: {str(e)}")

    return file_info


@st.cache_data(show_spinner=False)
def convert_video_to_audio_cached(file_hash, temp_video_path):
    """Convert video file to audio - cached based on file hash"""
    try:
        video = VideoFileClip(temp_video_path)

        if video.audio is None:
            video.close()
            raise ValueError("No audio track found in the video file")

        # Create temp audio file
        temp_audio_path = tempfile.mktemp(suffix=".wav")

        # Extract audio
        audio = video.audio
        audio.write_audiofile(temp_audio_path, logger=None)

        # Cleanup
        video.close()
        audio.close()

        # Get audio file info
        audio_size = os.path.getsize(temp_audio_path) / (1024 * 1024)

        return {
            "audio_path": temp_audio_path,
            "size_mb": audio_size,
            "success": True,
            "message": f"Audio extracted successfully! ({audio_size:.1f} MB)",
        }

    except Exception as e:
        return {
            "audio_path": None,
            "success": False,
            "message": f"Error extracting audio: {str(e)}",
        }


def stream_transcription_real(client, audio_file_path, language=None):
    """Real streaming transcription using gpt-4o-mini-transcribe"""
    try:
        with open(audio_file_path, "rb") as audio_file:
            stream = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=audio_file,
                response_format="text",
                language=language,
                stream=True,
            )

            for event in stream:
                print(f"Event {event}")  # Debugging output
                # Handle TranscriptionTextDeltaEvent objects
                if hasattr(event, 'delta') and event.delta:
                    yield event.delta
                elif hasattr(event, 'text') and event.text:
                    yield event.text
                elif isinstance(event, str):
                    yield event
                # Skip events without text content (like done events)

    except Exception as e:
        st.error(f"Transcription error: {str(e)}")
        yield f"Error: {str(e)}"


@st.cache_data(show_spinner=False)
def transcribe_audio_cached(file_hash, audio_path, language=None):
    """Transcribe audio file - cached based on file hash and language"""
    try:
        client = get_openai_client()
        with open(audio_path, "rb") as audio_file:
            response = client.audio.transcriptions.create(
                model="gpt-4o-mini-transcribe",
                file=audio_file,
                response_format="text",
                language=language,
            )
        return {"success": True, "text": response, "error": None}
    except Exception as e:
        return {"success": False, "text": "", "error": str(e)}


@st.cache_data(show_spinner=False)
def translate_text_cached(text_hash, text, target_language="English"):
    """Translate text - cached based on text hash and target language"""
    try:
        client = get_openai_client()
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": f"Translate the following text to {target_language}. Only return the translation, no additional text.",
                },
                {"role": "user", "content": text},
            ],
        )
        return {
            "success": True,
            "text": response.choices[0].message.content,
            "error": None,
        }
    except Exception as e:
        return {"success": False, "text": "", "error": str(e)}


def is_video_file(filename):
    """Check if file is a video file"""
    video_extensions = {".mp4", ".avi", ".mov", ".mkv", ".wmv", ".flv", ".webm", ".m4v"}
    return Path(filename).suffix.lower() in video_extensions


def is_audio_file(filename):
    """Check if file is a video file"""
    audio_extensions = {".mp3", ".wav", ".m4a", ".aac", ".ogg", ".flac", ".wma"}
    return Path(filename).suffix.lower() in audio_extensions


def stream_transcription(text, placeholder, label="Live Transcription"):
    """Simulate streaming text for better UX"""
    words = text.split()
    displayed_text = ""

    for i, word in enumerate(words):
        if i == 0:
            displayed_text = word
        else:
            displayed_text += " " + word

        placeholder.text_area(
            label,
            value=displayed_text,
            height=200,
            key=f"{label.lower().replace(' ', '_')}_{i}",
        )
        time.sleep(0.05)  # Small delay for streaming effect


def stream_translation(text, placeholder, target_language):
    """Simulate streaming translation for better UX"""
    words = text.split()
    displayed_text = ""

    for i, word in enumerate(words):
        if i == 0:
            displayed_text = word
        else:
            displayed_text += " " + word

        placeholder.text_area(
            f"Live Translation ({target_language})",
            value=displayed_text,
            height=200,
            key=f"translation_{target_language.lower()}_{i}",
        )
        time.sleep(0.05)


def main():
    st.set_page_config(
        page_title="Audio/Video Transcription & Translation",
        page_icon="üéµ",
        layout="wide",
    )

    st.title("üéµ Audio/Video Transcription & Translation")
    st.markdown(
        "Upload audio or video files for real-time transcription and translation"
    )

    # Sidebar for settings
    with st.sidebar:
        st.header("Settings")

        transcription_language = st.selectbox(
            "Transcription Language (optional)",
            options=[None, "en", "ar", "fr"],
            format_func=lambda x: "Auto-detect" if x is None else x,
            help="Leave as 'Auto-detect' for automatic language detection",
        )

        enable_translation = st.checkbox("Enable Translation", value=False)

        if enable_translation:
            target_language = st.selectbox(
                "Target Language",
                options=["English", "French", "German", "Spanish"],
                index=0,
            )

        api_key = st.text_input(
            "OpenAI API Key", type="password", help="Enter your OpenAI API key"
        )

        if api_key.strip() == "" or api_key is None:
            api_key = os.environ.get("OPENAI_API_KEY", "")

    st.header("üìÅ File Upload")

    uploaded_file = st.file_uploader(
        "Choose an audio or video file",
        type=[
            "mp3",
            "wav",
            "m4a",
            "aac",
            "ogg",
            "flac",
            "mp4",
            "avi",
            "mov",
            "mkv",
            "wmv",
            "webm",
        ],
        help="Supported formats: Audio (MP3, WAV, M4A, AAC, OGG, FLAC) and Video (MP4, AVI, MOV, MKV, WMV, WEBM)",
    )

    if uploaded_file:
        # Get file content and hash
        file_bytes = uploaded_file.read()
        file_hash = get_file_hash(file_bytes)

        # Reset processing state when new file is uploaded
        if st.session_state.current_file_hash != file_hash:
            st.session_state.conversion_complete = False
            st.session_state.processed_audio_path = None
            st.session_state.current_file_hash = file_hash
            st.session_state.transcription_complete = False
            st.session_state.transcription_text = ""
            st.session_state.translation_complete = False
            st.session_state.translation_text = ""

        st.success(f"‚úÖ File uploaded: {uploaded_file.name}")

        # Get cached file info
        with st.spinner("üìä Analyzing file..."):
            file_info = get_file_info(file_bytes, uploaded_file.name, file_hash)
            st.session_state.uploaded_file_info = file_info

        # Display file information
        display_file_info(file_info)

        # Conversion section
        st.header("üîÑ File Conversion")

        if file_info["is_video"] and not st.session_state.conversion_complete:
            st.info(
                "üé¨ Video file detected - conversion to audio required for transcription"
            )

            if st.button("üîÑ Convert Video to Audio", type="primary"):
                convert_video_file(file_info)

        elif file_info["is_audio"] and not st.session_state.conversion_complete:
            st.info("üéµ Audio file detected - preparing for transcription")

            if st.button("üìã Prepare Audio File", type="primary"):
                prepare_audio_file(file_info)

        elif st.session_state.conversion_complete:
            st.success("‚úÖ File conversion completed!")

            # Show audio file information
            if hasattr(st.session_state, "audio_file_info"):
                display_audio_info()

            # Processing section
            st.header("‚öôÔ∏è Transcription")

            if api_key:
                if not st.session_state.transcription_complete:
                    if st.button("üöÄ Start Transcription", type="primary"):
                        start_transcription(transcription_language)
                else:
                    st.success("‚úÖ Transcription completed!")
                    
                    # Show transcription result
                    st.text_area(
                        "Transcription Result",
                        value=st.session_state.transcription_text,
                        height=200,
                        key="final_transcription"
                    )
                    
                    # Translation section
                    st.header("üåê Translation (Optional)")
                    
                    if enable_translation:
                        if not st.session_state.translation_complete:
                            if st.button("üåê Start Translation", type="secondary"):
                                start_translation(target_language)
                        else:
                            st.success("‚úÖ Translation completed!")
                            st.text_area(
                                f"Translation Result ({target_language})",
                                value=st.session_state.translation_text,
                                height=200,
                                key="final_translation"
                            )
                    else:
                        st.info("üí° Enable translation in the sidebar to translate the transcription")
                    
                    # Download section
                    st.header("üíæ Download Results")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.download_button(
                            label="üìÑ Download Transcription",
                            data=st.session_state.transcription_text,
                            file_name=f"transcription_{st.session_state.uploaded_file_info['name']}.txt",
                            mime="text/plain",
                        )
                    
                    if st.session_state.translation_complete:
                        with col2:
                            st.download_button(
                                label="üåê Download Translation",
                                data=st.session_state.translation_text,
                                file_name=f"translation_{st.session_state.uploaded_file_info['name']}.txt",
                                mime="text/plain",
                            )
            else:
                st.warning("‚ö†Ô∏è Please enter your OpenAI API key in the sidebar")

    elif not uploaded_file:
        st.info("üëÜ Please upload a file to begin")


def display_file_info(file_info):
    """Display file information after upload"""
    col1, col2 = st.columns(2)

    with col1:
        st.write(f"**File size:** {file_info['size_mb']:.2f} MB")
        st.write(f"**Format:** {file_info['format'].upper()}")

    if file_info["is_video"]:
        with col2:
            if "duration" in file_info:
                duration_mins = file_info["duration"] / 60
                st.write(f"**Duration:** {duration_mins:.1f} minutes")
            if "resolution" in file_info:
                st.write(f"**Resolution:** {file_info['resolution']}")
            if "fps" in file_info:
                st.write(f"**FPS:** {file_info['fps']:.1f}")
            if "has_audio" in file_info:
                audio_status = "‚úÖ Yes" if file_info["has_audio"] else "‚ùå No"
                st.write(f"**Has Audio:** {audio_status}")

                if not file_info["has_audio"]:
                    st.error("‚ö†Ô∏è This video file has no audio track!")


def convert_video_file(file_info):
    """Convert video file to audio with progress tracking"""
    if not file_info.get("has_audio", True):
        st.error("‚ùå Cannot process video without audio track!")
        return

    # Show estimated time
    if "duration" in file_info:
        estimated_time = file_info["duration"] / 60 * 0.1
        st.info(f"‚è±Ô∏è Estimated conversion time: ~{estimated_time:.1f} minutes")

    # Create progress container
    progress_container = st.container()

    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()

        try:
            status_text.text("üé¨ Starting conversion...")
            progress_bar.progress(20)

            # Use cached conversion function
            conversion_result = convert_video_to_audio_cached(
                file_info["hash"], file_info["temp_path"]
            )

            progress_bar.progress(80)
            status_text.text("üßπ Finalizing...")

            if conversion_result["success"]:
                # Store processed audio path
                st.session_state.processed_audio_path = conversion_result["audio_path"]
                st.session_state.conversion_complete = True

                # Store audio file information
                audio_info = {
                    "name": f"{Path(file_info['name']).stem}.wav",
                    "format": ".wav",
                    "size_mb": conversion_result["size_mb"],
                    "temp_path": conversion_result["audio_path"],
                    "is_audio": True,
                }
                st.session_state.audio_file_info = audio_info

                progress_bar.progress(100)
                status_text.text("‚úÖ Audio extraction completed!")

                st.success(conversion_result["message"])

                # Clear progress after a moment
                time.sleep(1)
                progress_bar.empty()
                status_text.empty()

                # Rerun to update UI
                st.rerun()
            else:
                st.error(conversion_result["message"])
                progress_bar.empty()
                status_text.empty()

        except Exception as e:
            st.error(f"‚ùå Unexpected error: {str(e)}")
            progress_bar.empty()
            status_text.empty()


def prepare_audio_file(file_info):
    """Prepare audio file for transcription"""
    with st.spinner("üìã Preparing audio file..."):
        # For audio files, we just use the uploaded file directly
        st.session_state.processed_audio_path = file_info["temp_path"]
        st.session_state.conversion_complete = True

        # Store audio file information (same as original for audio files)
        st.session_state.audio_file_info = file_info.copy()

        time.sleep(0.5)  # Brief pause for user feedback
        st.success("‚úÖ Audio file prepared for transcription!")

        # Rerun to update UI
        st.rerun()


def display_audio_info():
    """Display audio file information after conversion"""
    st.subheader("üéµ Audio File Information")
    audio_info = st.session_state.audio_file_info

    col1, col2 = st.columns(2)
    with col1:
        st.write(f"**Audio file:** {audio_info['name']}")
        st.write(f"**Format:** {audio_info['format'].upper()}")
        st.write(f"**Size:** {audio_info['size_mb']:.2f} MB")

    with col2:
        if "duration" in audio_info:
            duration_mins = audio_info["duration"] / 60
            st.write(f"**Duration:** {duration_mins:.1f} minutes")
        st.write(f"**Ready for transcription:** ‚úÖ")


def start_transcription(transcription_language):
    """Start the transcription process with real streaming"""
    if not st.session_state.processed_audio_path:
        st.error("‚ùå No audio file available for transcription")
        return

    client = get_openai_client()

    # Create container for real-time updates
    transcription_container = st.container()

    with transcription_container:
        st.subheader("üìù Live Transcription")
        transcription_placeholder = st.empty()

    try:
        # Start real streaming transcription
        st.info("üéôÔ∏è Starting live transcription...")
        
        full_transcription = ""
        
        # Real streaming from OpenAI API
        for chunk in stream_transcription_real(
            client, st.session_state.processed_audio_path, transcription_language
        ):
            if chunk and not chunk.startswith("Error:"):
                full_transcription += chunk
                
                # Update the display in real-time
                transcription_placeholder.text_area(
                    "Live Transcription Stream",
                    value=full_transcription,
                    height=200,
                    key=f"live_transcription_{len(full_transcription)}",
                )
                
                # Small delay to make streaming visible
                time.sleep(0.01)
            elif chunk and chunk.startswith("Error:"):
                st.error(chunk)
                return

        # Store transcription results
        st.session_state.transcription_text = full_transcription
        st.session_state.transcription_complete = True
        
        st.success("‚úÖ Transcription completed!")
        
        # Rerun to show the next steps
        st.rerun()

    except Exception as e:
        st.error(f"‚ùå Error during transcription: {str(e)}")


def start_translation(target_language):
    """Start the translation process"""
    if not st.session_state.transcription_text:
        st.error("‚ùå No transcription available for translation")
        return

    try:
        st.info(f"üåê Starting translation to {target_language}...")

        # Get cached translation
        text_hash = hashlib.md5(st.session_state.transcription_text.encode()).hexdigest()
        translation_result = translate_text_cached(
            text_hash, st.session_state.transcription_text, target_language
        )

        if translation_result["success"]:
            # Store translation results
            st.session_state.translation_text = translation_result["text"]
            st.session_state.translation_complete = True
            
            st.success("‚úÖ Translation completed!")
            
            # Rerun to show the translation result
            st.rerun()
        else:
            st.error(f"Translation error: {translation_result['error']}")

    except Exception as e:
        st.error(f"‚ùå Error during translation: {str(e)}")


if __name__ == "__main__":
    main()
